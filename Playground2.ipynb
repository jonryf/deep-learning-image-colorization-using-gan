{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn import init\n",
    "\n",
    "from settings import EPOCHS\n",
    "from unet import UNET\n",
    "from Discriminator import Discriminator\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import BCELoss, L1Loss, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer):\n",
    "    \n",
    "    def lambda_rule(epoch):\n",
    "        lr_l = 1.0 - max(0, epoch + 1 - EPOCHS) / float(EPOCHS + 1)\n",
    "        return lr_l\n",
    "    \n",
    "    return lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "\n",
    "def update_learning_rate(scheduler, optimizer):\n",
    "    scheduler.step()\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print('learning rate = %.7f' % lr)\n",
    "\n",
    "def trainPix2Pix(model, data, totalEpochs=EPOCHS, genLr=0.0001, descLr=0.00005):\n",
    "    genOptimizer = Adam( list(model.gen.parameters()), lr=0.0001)\n",
    "    discOptimizer = Adam( list(model.disc.parameters()), lr=0.00005)\n",
    "    \n",
    "    net_g_scheduler = get_scheduler(genOptimizer)\n",
    "    net_d_scheduler = get_scheduler(discOptimizer)\n",
    "\n",
    "    \n",
    "    criterion = MSELoss().cuda()\n",
    "    criterionL1 = L1Loss().cuda()\n",
    "\n",
    "    model.gen.train()\n",
    "    model.disc.train()\n",
    "    for epoch in range(totalEpochs):\n",
    "        print(\"Epoch \" + str(epoch))\n",
    "        for minibatch, (color_and_gray, gray_three_channel) in enumerate(data):\n",
    "            train_step(model, color_and_gray.cuda(), gray_three_channel.cuda(), criterion, genOptimizer, discOptimizer, criterionL1)\n",
    "            if minibatch > 10:\n",
    "                break\n",
    "        \n",
    "        update_learning_rate(net_g_scheduler, genOptimizer)\n",
    "        update_learning_rate(net_d_scheduler, discOptimizer)\n",
    "\n",
    "# assumes minibatch is only colord images.\n",
    "def train_step(model, color, black_white, criterion, gen_optimizer, disc_optimizer, criterion_l1):    \n",
    "    # generate images\n",
    "    generated = model.generate(black_white)\n",
    "    \n",
    "    disc_optimizer.zero_grad()\n",
    "    \n",
    "    input_output = torch.cat((black_white, generated), 1)\n",
    "    input_target = torch.cat((black_white, color), 1)\n",
    "    \n",
    "    # train with generated   \n",
    "    pred_generated = model.discriminate(input_output.data)\n",
    "    generated_labels = torch.tensor(0).expand_as(pred_generated).cuda()\n",
    "    loss_false = criterion(pred_generated, generated_labels.float())\n",
    "    \n",
    "    # train with target\n",
    "    pred_targets = model.discriminate(input_target)\n",
    "    targets_labels = torch.tensor(1).expand_as(pred_targets).cuda()\n",
    "    loss_true = criterion(pred_targets, targets_labels.float())\n",
    "    \n",
    "    print(\"Loss false: {} Loss true {}: \".format(loss_false, loss_true))\n",
    "    loss_discriminator = (loss_false + loss_true) / 2\n",
    "    loss_discriminator.backward()\n",
    "    disc_optimizer.step()\n",
    "\n",
    "    \n",
    "    gen_optimizer.zero_grad()\n",
    "    pred_output =  model.discriminate(input_output) \n",
    "\n",
    "    loss_gen = criterion(pred_output, targets_labels.float())\n",
    "    # G(A) = B\n",
    "    loss_ab = criterion_l1(black_white, color) * 1 # weight, L1 term \n",
    "\n",
    "    loss_gen = (loss_gen + loss_ab)/2\n",
    "    \n",
    "    loss_gen.backward()\n",
    "    gen_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class pix2pix(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(pix2pix, self).__init__()\n",
    "        numclasses = 3 #RGB\n",
    "        numchannels = 64\n",
    "        self.gen = UNET(numclasses, numchannels)\n",
    "        self.disc = Discriminator()\n",
    "#         self.criterion = CrossEntropyLoss()\n",
    "        self.writer = SummaryWriter('runs/pix2pix')\n",
    "\n",
    "    def log_image(self, images):\n",
    "        # write to tensorboard\n",
    "        img_grid = torchvision.utils.make_grid(images)\n",
    "        self.writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "\n",
    "    def log_metrics(self, epoch, loss):\n",
    "        self.writer.add_scalar('training loss', loss, epoch)\n",
    "        self.trainData.append(loss)\n",
    "\n",
    "    def generate(self, greyscale):\n",
    "        return self.gen(greyscale)\n",
    "        #Need to add dropout\n",
    "\n",
    "    def discriminate(self, img):\n",
    "        #(images, features, height, width)\n",
    "        # Return average - 1 value for all images\n",
    "        ret = self.disc(img)\n",
    "        ret = torch.mean(ret, axis=2)\n",
    "        ret = torch.mean(ret, axis=2)\n",
    "        return ret\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/cs253wi20an/PA5/dataloader.py\", line 73, in __getitem__\n    color_and_gray = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(color_and_gray)\n  File \"/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 209, in normalize\n    raise TypeError('tensor is not a torch image.')\nTypeError: tensor is not a torch image.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7df33831715f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/cs253wi20an/PA5/dataloader.py\", line 73, in __getitem__\n    color_and_gray = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(color_and_gray)\n  File \"/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 209, in normalize\n    raise TypeError('tensor is not a torch image.')\nTypeError: tensor is not a torch image.\n"
     ]
    }
   ],
   "source": [
    "def TenToPic(image):\n",
    "    s = image.size()\n",
    "    ret = torch.zeros(s[1], s[2], s[0])\n",
    "    for i in range(s[0]):\n",
    "        ret[:, :, i] = image[i, :,:]\n",
    "    return ret.detach().numpy().astype(int)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "from utils import get_datasets\n",
    "train_dataset, test_dataset = get_datasets()\n",
    "ex = None\n",
    "for i in train_dataset:\n",
    "    ex = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pix2pix().cuda()\n",
    "# out = model.generate(ex[1])\n",
    "# plt.imshow(TenToPic(out[0,:,:,:]))\n",
    "# plt.figure()\n",
    "# plt.imshow(out.detach().numpy()[0,0,:,:])\n",
    "plt.figure()\n",
    "plt.imshow(TenToPic(ex[0][0,:,:,:]))\n",
    "plt.figure()\n",
    "plt.imshow(TenToPic(ex[1][0,:,:,:]))\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cpuModel = model.cpu()\n",
    "out = model.generate(ex[1]) * 255\n",
    "plt.imshow(TenToPic(out[0,:,:,:]))\n",
    "plt.figure()\n",
    "plt.imshow(out.detach().numpy()[0,0,:,:])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPix2Pix(model, train_dataset, totalEpochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuModel = model.cpu()\n",
    "out = model.generate(ex[1]).squeeze(0)\n",
    "plt.figure()\n",
    "plt.imshow(TenToPic(ex[1][:,:,:]))\n",
    "plt.figure()\n",
    "plt.imshow(TenToPic((out[:,:,:])))\n",
    "plt.figure()\n",
    "plt.imshow(out.detach().numpy()[0,0,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(out.detach().numpy()[0,1,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(out.detach().numpy()[0,2,:,:])\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "model.cuda()\n",
    "temp = 1\n",
    "plt.figure()\n",
    "plt.imshow(TenToPic(ex[0][0,:,:,:]))\n",
    "import pytorch_ssim\n",
    "print(\"-----------\")\n",
    "#print(pytorch_ssim.ssim(out[:,:,:,:], ex[0][:,:,:,:]))\n",
    "#print(pytorch_ssim.ssim(ex[0][:,:,:,:], ex[0][:,:,:,:]))\n",
    "\n",
    "diff = out[0,0,:,:] - out[0,1,:,:]\n",
    "plt.figure()\n",
    "plt.imshow(diff[:,:].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
